position = position_dodge(width = .9)) +
# Adjust titles as you see fit
labs(title = "Is a multiple-item purchase on a credit card a signal for fraud?",
y = "Fraud Proportion",
x = "Was there more than one purchase?") +
my_theme
5.8 - 1.2
4.6 / 1.2
# Loading in Data
# For this script, preset X as your groups to compare and Y as your target
data <- read_csv("medical_costs.csv") %>%
filter(Smoker == "no") %>%
rename(Y = `Medical Cost`, X = BMI) %>%
select(X, Y)
# Change to binary for groups if needed
data$X <- ifelse(data$X > 25, T, F) # unhealthy according to national BMI index
### Step 1: Hypothesis Test
# We believe pre-study that there is no difference among X groups by Y.
# In other words, the expected difference between X in Y is 0
exp_difference <- 0
# The alternative would be that at least one group has significantly different
# costs than another. This is called a two-way test. We will specify this test with
# a significance level of 0.05.
alpha = .05
### Step 2: Post-study EDA
bw <- 250
n <- nrow(data)
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .5, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Medical Cost by Smoking History",
y = "Count", x = "Medical Cost", fill = "Is High BMI") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .5, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .25, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .75, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = 1, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .1, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .25, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), color = X, fill = X)) +
geom_histogram(alpha = .25, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .25, binwidth = bw, position = 'identity') +
geom_density(alpha = 0, mapping = aes(color = X, y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .25, binwidth = bw, position = 'identity') +
geom_density(show.legend = F, alpha = 0, mapping = aes(color = X, y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
ggplot(data = data, mapping = aes(x = Y, y = after_stat(count), fill = X)) +
geom_histogram(alpha = .35, binwidth = bw, position = 'identity') +
geom_density(show.legend = F, alpha = 0, mapping = aes(color = X, y = after_stat(bw*n*density))) +
scale_x_continuous(labels = scales::dollar, breaks = seq(0,25000,2500)) +
# adjust these titles as you see fit
labs(title = "Is BMI correlated to higher medical expenses?",
y = "Frequency", x = "Medical Cost", fill = "Overweight") +
my_theme
data <- read_csv("https://www.kaggle.com/datasets/younusmohamed/payment-fraud-empowering-financial-security?select=payment_fraud.csv")
data
library(vroom)
data <- vroom("https://www.kaggle.com/datasets/younusmohamed/payment-fraud-empowering-financial-security?select=payment_fraud.csv")
library(tidymodels)
g1
?prop.test
prop.test(x = c(g1$Sum, g2$Sum),
n = c(g2$N, g2$N),
alternative = "two.sided")$p.value
prop.test(x = c(g1$Sum, g2$Sum),
n = c(g2$N, g2$N),
alternative = "two.sided")
paste("[", lwr, ", ", upr, "]", sep = "")
prop.test(x = c(g1$Sum, g2$Sum),
n = c(g1$N, g2$N),
alternative = "two.sided")
paste("[", lwr, ", ", upr, "]", sep = "")
# Compute unpooled SE
x1 <- g1$Sum
x2 <- g2$Sum
n1 <- g1$N
n2 <- g2$N
p1 <- g1$Prop
p2 <- g2$Prop
x1
x2
prop.test(x = c(x1, x2),
n = c(n1, n2),
alternative = "two.sided")
paste("[", lwr, ", ", upr, "]", sep = "")
prop.test(x = c(x1, x2),
n = c(n1, n2),
alternative = "two.sided",
correct = F)
paste("[", lwr, ", ", upr, "]", sep = "")
prop.test(x = c(x1, x2),
n = c(n1, n2),
alternative = "two.sided",
correct = T)
prop.test(x = c(x1, x2),
n = c(n1, n2),
alternative = "two.sided",
correct = F)
# We start with computing the observed
obs_difference <- abs(g1$Prop - g2$Prop)
# Compute unpooled SE
x1 <- g1$Sum
x2 <- g2$Sum
n1 <- g1$N
n2 <- g2$N
p1 <- g1$Prop
p2 <- g2$Prop
SE <- sqrt(((p1) * (1 - p1)) / n1 + ((p2) * (1 - p2)) / n2)
# Compute critical value and p-value
z_val <- (obs_difference - exp_difference) / SE
p_val <- 2*pnorm(q = abs(z_val), lower.tail = F) # multiply by 2 for two-sided
paste("Z-score", round(z_val, 2))
paste("p-value", p_val) # definitely significant
# Compute confidence interval of difference
lwr = obs_difference - qnorm(1-alpha/2) * SE
upr = obs_difference + qnorm(1-alpha/2) * SE
paste("Observed Difference")
paste(obs_difference)
paste("Observed Difference Confidence Interval:")
paste("[", lwr, ", ", upr, "]", sep = "")
prop.test(x = c(x1, x2),
n = c(n1, n2),
alternative = "two.sided",
correct = F)
# Compute unpooled SE
x1 <- g1$Sum
x2 <- g2$Sum
n1 <- g1$N
n2 <- g2$N
p1 <- g1$Prop
p2 <- g2$Prop
SE_u <- sqrt(((p1) * (1 - p1)) / n1 + ((p2) * (1 - p2)) / n2)
# ... or compute pooled sample proportion (p_hat) and standard error
p_hat <- (g1$Sum + g2$Sum) / (n1 + n2)
SE_p <- sqrt(p_hat * (1-p_hat) * (1/n1 + 1/n2))
# Compute critical value and p-value
z_val <- (obs_difference - exp_difference) / SE_p
p_val <- 2*pnorm(q = abs(z_val), lower.tail = F) # multiply by 2 for two-sided
paste("Z-score", round(z_val, 2))
paste("p-value", p_val) # definitely significant
# Compute confidence interval of difference
lwr = obs_difference - qnorm(1-alpha/2) * SE_u
upr = obs_difference + qnorm(1-alpha/2) * SE_u
paste("Observed Difference")
paste(obs_difference)
paste("Observed Difference Confidence Interval:")
paste("[", lwr, ", ", upr, "]", sep = "")
prop.test(x = c(x1, x2),
n = c(n1, n2),
alternative = "two.sided",
correct = F)
prop.test(x = c(x1, x2),
n = c(n1, n2),
alternative = "two.sided",
correct = F)$p.value
paste("p-value", p_val) # definitely significant
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = T)
paste("[", lwr, ", ", upr, "]", sep = "")
data
data <- read_csv("payment_fraud.csv") %>%
rename(X = numItems, Y = label) %>%
select(X, Y)
# Change to binary for groups if needed
data$Y <- ifelse(data$Y == 1, T, F) # is smoker
data$X <- ifelse(data$X > 1, T, F) # number of purchases > 1
data %>% prop_test(Y ~ X)
data %>% prop_test(Y ~ X, order = c(T, F))
data %>% prop_test(Y ~ X, order = c("TRUE", "FALSE"))
paste("[", lwr, ", ", upr, "]", sep = "")
data %>% prop_test(Y ~ X, order = c("TRUE", "FALSE"), correct = F)
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = F)$p.value
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = T)$p.value
data %>%
prop_test(Y ~ X, order = c("TRUE", "FALSE"), correct = F, z = TRUE)
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = F)
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = F, z = T)
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = F)
261^.5
z_val
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = F)
z_val^2
data %>%
prop_test(Y ~ X, order = c("TRUE", "FALSE"),
correct = F, z = TRUE)
group_stats
g1$N * g1$Prop > 5
g1$N * g1$Prop
g1$N * (1-g1$Prop)
g2$N * g2$Prop
g2$N * (1-g2$Prop)
g1$N * g1$Prop > 5
g1$N * (1-g1$Prop) > 5
g2$N * g2$Prop > 5
g2$N * (1-g2$Prop) > 5
g1$N
g2$N
gA <- group_stats[2,] # TRUE
gB <- group_stats[1,] # FALSE
exp_diff <- 0 # h0
obs_diff <- gA$Prop - gB$prop
alpha <- 0.05 # cutoff
exp_diff <- 0 # h0
obs_diff <- gA$Prop - gB$Prop
alpha <- 0.05 # cutoff
obs_diff
gA$N * gA$Prop > 5
gA$N * (1-gA$Prop) > 5
gB$N * gB$Prop > 5
gB$N * (1-gB$Prop) > 5
SE_u <- sqrt(((gA$Prop) * (1 - gA$Prop)) / gA$N + ((gB$Prop) * (1 - gB$Prop)) / gB$N)
SE_p
p_hat <- (gA$Sum + gB$Sum) / (gA$N + gB$N)
SE_p <- sqrt(p_hat * (1-p_hat) * (1/gA$N + 1/gB$N))
SE_p
paste("p-value", round(p_val, 4)) # definitely significant
p_val
paste("p-value", p_val) # definitely significant
paste("stat sig", p_val < alpha) #
# Compute confidence interval of difference
lwr = obs_difference - qnorm(1-alpha/2) * SE_u
upr = obs_difference + qnorm(1-alpha/2) * SE_u
paste("Observed Difference")
paste(obs_difference)
paste("Observed Difference Confidence Interval:")
paste("[", lwr, ", ", upr, "]", sep = "")
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = F)
paste("[", lwr, ", ", upr, "]", sep = "")
prop.test(x = c(gA$Sum, gB$Sum), n = c(gA$N, gB$N),
alternative = "two.sided",
correct = F)
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = F)
data %>%
prop_test(Y ~ X, order = c("TRUE", "FALSE"),
correct = F, z = TRUE)
prop.test(x = c(x1, x2), n = c(n1, n2),
alternative = "two.sided",
correct = F)
# find the point estimate
point_estimate <- data %>%
specify(response = Y) %>%
calculate(stat = "prop")
# find the point estimate
point_estimate <- data %>%
specify(response = Y, success = T) %>%
calculate(stat = "prop")
# find the point estimate
point_estimate <- data %>%
specify(response = Y, success = 'TRUE') %>%
calculate(stat = "prop")
point_estimate
?specify
# find the point estimate
point_estimate <- data %>%
specify(Y ~ X, success = 'TRUE') %>%
calculate(stat = "prop")
# find the point estimate
point_estimate <- data %>%
specify(response = Y, explanatory = X, success = 'TRUE') %>%
calculate(stat = "prop")
?calculate
data
colSums(data)
point_estimate <- data %>%
specify(response = Y, explanatory = X, success = 'TRUE') %>%
calculate(stat = "prop")
# find the point estimate
point_estimate <- data %>%
specify(response = Y, explanatory = X, success = 'TRUE') %>%
calculate(stat = "diff in props")
# find the point estimate
point_estimate <- data %>%
specify(Y ~ X, success = 'TRUE') %>%
calculate(stat = "diff in props", order = c("TRUE", "FALSE"))
point_estimate
data %>%
specify(Y ~ X) %>%
hypothesize(null = "point", mu = 0)
?hypothesize
data %>%
specify(Y ~ X) %>%
hypothesize(null = "independence", p = 0)
data %>%
specify(Y ~ X, success = "TRUE")
data %>%
specify(Y ~ X, success = "TRUE") %>%
hypothesize(null = "independence", p = 0)
data %>%
specify(Y ~ X, success = "TRUE") %>%
hypothesize(null = "independence")
data %>%
specify(Y ~ X, success = "TRUE") %>%
hypothesize(null = "independence") %>%
generate(reps = 5000, type = "bootstrap")
data %>%
specify(Y ~ X, success = "TRUE") %>%
hypothesize(null = "independence") %>%
generate(reps = 500, type = "bootstrap")
data %>%
specify(Y ~ X, success = "TRUE") %>%
hypothesize(null = "independence") %>%
generate(reps = 500, type = "bootstrap")
# generate a null distribution
null_dist <- data %>%
specify(Y ~ X, success = "TRUE") %>%
hypothesize(null = "independence") %>%
generate(reps = 500, type = "bootstrap") %>%
calculate(stat = "diff in props")
# generate a null distribution
null_dist <- data %>%
specify(Y ~ X, success = "TRUE") %>%
hypothesize(null = "independence") %>%
generate(reps = 500, type = "bootstrap") %>%
calculate(stat = "diff in props", order = c("TRUE", "FALSE"))
null_dist %>%
visualize() +
shade_p_value(obs_stat = point_estimate, direction = "two_sided")
# 1. Compute observed difference in proportions
point_estimate <- data %>%
specify(Y ~ X, success = 'TRUE') %>%
calculate(stat = "diff in props", order = c("TRUE", "FALSE"))
obs_stat <- point_estimate$stat
# 2. Generate null distribution under independence
null_dist <- data %>%
specify(Y ~ X, success = 'TRUE') %>%
hypothesize(null = "independence") %>%
generate(reps = 500, type = "permute") %>%
calculate(stat = "diff in props", order = c("TRUE", "FALSE"))
# 3. Visualize null and shade p-value
null_dist %>%
visualize() +
shade_p_value(obs_stat = obs_stat, direction = "two_sided")
library(googlesheets4)
library(tidyverse)
setwd("../TourneyManager")
source("functions.R")
# set stack to TRUE to print all games/pools on one sheet
# set stack to FALSE for printing each pool per sheet
# set stack to "BOTH" to have both stacked and pool specific
stack <- "BOTH" # SET HERE
# copy/paste the link to the "Teams List" sheet
# SET LINK HERE
link <- 'https://docs.google.com/spreadsheets/d/1Kts2f_saFQF4_kcMH_X1t_nf0IRRT0uAxYvIgjE8VWU/edit?gid=96325893#gid=96325893'
# authentication required, follow instructions given
tourney_info <- read_sheet(link, sheet = "Teams List", range = "A2:D")
pools <- unique(tourney_info$Pool)
pools
max_games <- as.numeric(colnames(tourney_info)[4])
max_games
matchups <- list()
for (pool in pools){
# pull teams in selected pool
teams <- tourney_info %>%
filter(Pool == pool) %>%
pull(`Team Name`)
# create round robin matchups
rr <- round_robin(teams = teams, alphabetical = F)
# convert to df
rr_df <- to_df(rr)
# filter to max_games only
rr_df_lim <- rr_df %>%
mutate(Round_Int = str_extract(Round, "\\d")) %>%
filter(Round_Int <= max_games) %>%
select(-Round_Int)
# save results
matchups[[pool]] <- rr_df_lim
}
print(matchups[[pools[1]]]) # check if it looks good
# write to google sheet
to_sheets(matchups, link, stack)
# set stack to TRUE to print all games/pools on one sheet
# set stack to FALSE for printing each pool per sheet
# set stack to "BOTH" to have both stacked and pool specific
stack <- "BOTH" # SET HERE
# copy/paste the link to the "Teams List" sheet
# SET LINK HERE
link <- 'https://docs.google.com/spreadsheets/d/1Kts2f_saFQF4_kcMH_X1t_nf0IRRT0uAxYvIgjE8VWU/edit?gid=96325893#gid=96325893'
# authentication required, follow instructions given
tourney_info <- read_sheet(link, sheet = "Teams List", range = "A2:D")
pools <- unique(tourney_info$Pool)
max_games <- as.numeric(colnames(tourney_info)[4])
matchups <- list()
for (pool in pools){
# pull teams in selected pool
teams <- tourney_info %>%
filter(Pool == pool) %>%
pull(`Team Name`)
# create round robin matchups
rr <- round_robin(teams = teams, alphabetical = F)
# convert to df
rr_df <- to_df(rr)
# filter to max_games only
rr_df_lim <- rr_df %>%
mutate(Round_Int = str_extract(Round, "\\d")) %>%
filter(Round_Int <= max_games) %>%
select(-Round_Int)
# save results
matchups[[pool]] <- rr_df_lim
}
print(matchups[[pools[1]]]) # check if it looks good
# write to google sheet
to_sheets(matchups, link, stack)
# set stack to TRUE to print all games/pools on one sheet
# set stack to FALSE for printing each pool per sheet
# set stack to "BOTH" to have both stacked and pool specific
stack <- "BOTH" # SET HERE
# copy/paste the link to the "Teams List" sheet
# SET LINK HERE
link <- 'https://docs.google.com/spreadsheets/d/1Kts2f_saFQF4_kcMH_X1t_nf0IRRT0uAxYvIgjE8VWU/edit?gid=96325893#gid=96325893'
# authentication required, follow instructions given
tourney_info <- read_sheet(link, sheet = "Teams List", range = "A2:D")
pools <- unique(tourney_info$Pool)
max_games <- as.numeric(colnames(tourney_info)[4])
matchups <- list()
for (pool in pools){
# pull teams in selected pool
teams <- tourney_info %>%
filter(Pool == pool) %>%
pull(`Team Name`)
# create round robin matchups
rr <- round_robin(teams = teams, alphabetical = F)
# convert to df
rr_df <- to_df(rr)
# filter to max_games only
rr_df_lim <- rr_df %>%
mutate(Round_Int = str_extract(Round, "\\d")) %>%
filter(Round_Int <= max_games) %>%
select(-Round_Int)
# save results
matchups[[pool]] <- rr_df_lim
}
print(matchups[[pools[1]]]) # check if it looks good
# write to google sheet
to_sheets(matchups, link, stack)
